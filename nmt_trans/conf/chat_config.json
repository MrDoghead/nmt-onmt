{
  "raw_org_data": "/data/translate/hb_trans/raw_para_corpus/all_1kw",
  "raw_tag_data": "data/offline_data/raw_para_corpus/all_1kw_tagged_v2",
  "preped_dir": "data/offline_data/prep_corpus/prep_1kw_tagged_v2",
  "preped_base_name": "all",
  "tmp_dst_train_path": "data/offline_data/tmp/dst_train.csv",
  "tmp_dst_test_path": "data/offline_data/tmp/dst_test.csv",
  "tmp_tot_word_path": "data/offline_data/tmp/tran_word_file.csv",
  "bpe_code_path": "data/online_data/bpe_codes",
  "src_train_path": "data/offline_data/src_train_info.csv",
  "src_test_path": "data/offline_data/src_test_info.csv",
  "dst_train_path": "data/offline_data/dst_train.csv",
  "dst_test_path": "data/offline_data/dst_test.csv",
  "train_info":{
    "train_fmt_path": "data/offline_data/nmt_fmt/cht",
    "src_seq_length": 200,
    "tgt_seq_length": 200,
    "layers": 4,
    "rnn_size": 512,
    "word_vec_size": 512,
    "transformer_ff": 2048,
    "heads": 8,
    "encoder_type": "transformer",
    "decoder_type": "transformer",
    "position_encoding": null,
    "train_steps": 200000,
    "max_generator_batches": 2,
    "dropout": 0.1,
    "batch_size": 1024,
    "valid_batch_size": 128,
    "batch_type": "tokens",
    "normalization": "tokens",
    "accum_count": 4,
    "optim": "adam",
    "adam_bta2": 0.998,
    "decay_method": "noam",
    "warmup_steps": 16000,
    "learing_rate": 2,
    "max_grad_norm": 0,
    "param_init": 0,
    "param_init_glorot": null,
    "label_smoothing": 0.1,
    "valid_steps": 5000,
    "save_checkpoint_steps": 5000,
    "world_size": 4,
    "gpu_ranks": [0, 1, 2, 3]
  },
  "model_path": "data/online_data/model_bin/nmt/cht",
  "eval_info": {
    "model_suffix": "_step_85000.pt",
    "replace_unk": null,
    "verbose": null,
    "output": "data/offline_data/test_pred.cht"
  },
  "pred_info": {
    "c_model_path": "data/online_data/model_bin/nmt/c_trans.pt",
    "model_spec": "TransformerBase"
  }
}
